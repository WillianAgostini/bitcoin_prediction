{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-06 13:09:44.844267: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-06 13:09:44.844296: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# !pip install requests zipfile36\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.layers import Dense, LSTM, CuDNNLSTM, Dropout, GRU, Bidirectional, Input, Embedding, Activation\n",
    "from keras.models import Sequential, Model, clone_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt  # data visualization\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "import statsmodels.api as sm\n",
    "import importlib\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import plotly.offline as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from itertools import cycle\n",
    "import math\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "showGraphs = False\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "# https://towardsdatascience.com/cryptocurrency-price-prediction-using-lstms-tensorflow-for-hackers-part-iii-264fcdbccd3f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt  # data visualization\n",
    "import numpy as np  # linear algebra\n",
    "from matplotlib import ticker\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def getFirstTimestamp(data):\n",
    "    if 'dateHour' in data.columns:\n",
    "        return data[\"dateHour\"][:1]\n",
    "\n",
    "    if 'Timestamp' in data.columns:\n",
    "        timestamp = data[\"Timestamp\"][:1].values[0]\n",
    "        return datetime.fromtimestamp(timestamp).strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "    return datetime.fromtimestamp(data.index[:1][0]).strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "def getLastTimestamp(data):\n",
    "    if 'dateHour' in data.columns:\n",
    "        return data[\"dateHour\"][-1:]\n",
    "\n",
    "    if 'Timestamp' in data.columns:\n",
    "        timestamp = data[\"Timestamp\"][-1:].values[0]\n",
    "        return datetime.fromtimestamp(timestamp).strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "    return datetime.fromtimestamp(data.index[-1:][0]).strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "def filterByInterval(coinbase, relativeDelta):\n",
    "    \"\"\"\n",
    "    Filter data by interval\n",
    "    example: relativedelta => years=0, days=30\n",
    "    \"\"\"\n",
    "\n",
    "    lastTimestamp = coinbase[\"Timestamp\"][-1:].values[0]\n",
    "    endTimestampToFilter = lastTimestamp\n",
    "\n",
    "    interval = (datetime.fromtimestamp(lastTimestamp) -\n",
    "                relativeDelta).timestamp()\n",
    "\n",
    "    values = coinbase[coinbase[\"Timestamp\"] > interval]\n",
    "    return values[values[\"Timestamp\"] <= endTimestampToFilter]\n",
    "\n",
    "\n",
    "def separateTrainTest(data, relativeDeltaSubtract):\n",
    "    \"\"\"\n",
    "    Filter filtered by interval\n",
    "    relativeDeltaSubtract: Subtrai um intervalo de data para filtrar os dados\n",
    "    restante dos dados retorna como dados para treinameto\n",
    "    example: relativeDeltaSubtract => years=0, days=30\n",
    "    \"\"\"\n",
    "    lastTimestamp = data[\"Timestamp\"][-1:].values[0]\n",
    "\n",
    "    startTimestampToDataTest = (datetime.fromtimestamp(\n",
    "        lastTimestamp) - relativeDeltaSubtract).timestamp()\n",
    "\n",
    "    test = data.loc[data[\"Timestamp\"] > startTimestampToDataTest].copy()\n",
    "    train = data.loc[data[\"Timestamp\"] <= startTimestampToDataTest].copy()\n",
    "\n",
    "    test = test['Close'].values.reshape(-1, 1)\n",
    "    train = train['Close'].values.reshape(-1, 1)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def scaller(df):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(df)\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def create_dataset(df, look_back=1):\n",
    "    scaled = scaller(df)\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(scaled) - look_back):\n",
    "        a = scaled[i:(i + look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(scaled[i + look_back, 0])\n",
    "    \n",
    "    X = np.array(dataX)\n",
    "    X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
    "    Y = np.array(dataY)\n",
    "    return X, Y\n",
    "\n",
    "def create_dataset2(training_set):\n",
    "    training_set = np.reshape(training_set, (len(training_set), 1))\n",
    "    sc = MinMaxScaler()\n",
    "    training_set = sc.fit_transform(training_set)\n",
    "    X = training_set[0:len(training_set)-1]\n",
    "    Y = training_set[1:len(training_set)]\n",
    "    X = np.reshape(X, (len(X), 1, 1))\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def dropColumns(data, expectedColumns):\n",
    "    for column in data.columns:\n",
    "        if column not in expectedColumns:\n",
    "            data.drop(column, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "def hasMissingData(timestampList):\n",
    "    \"\"\"\n",
    "    Verifica se possui intervalos diferentes de 60 segundos comparando o valor do iterador atual do array com o iterador anterior.\n",
    "\n",
    "    Parameters:\n",
    "        timestampList: Lista de valores timestamp -> list\n",
    "\n",
    "    Return:\n",
    "        False se não possui dados faltantes. True caso exista -> bool\n",
    "    \"\"\"\n",
    "    missing = []\n",
    "    for i in range(len(timestampList)):\n",
    "        if i > 0 and (timestampList[i] - timestampList[i - 1] != 60):\n",
    "            missing.append(\"{} {}\".format(i, datetime.fromtimestamp(\n",
    "                timestampList[i]), datetime.fromtimestamp(timestampList[i - 1])))\n",
    "\n",
    "    if len(missing) == 0:\n",
    "        return False\n",
    "\n",
    "    print(\"Intervalos sem registros:\")\n",
    "    for i in missing:\n",
    "        print(i)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def annot_max(x, y,  posX, posY, connectionstyle=\"angle,angleA=0,angleB=60\", ax=None, mask=\"${:,.2f}\"):\n",
    "    text = mask.format(y)\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "    arrowprops = dict(\n",
    "        arrowstyle=\"->\", connectionstyle=connectionstyle)\n",
    "    kw = dict(xycoords='data', textcoords=\"data\",\n",
    "              arrowprops=arrowprops, bbox=bbox_props, ha=\"left\", va=\"top\", fontsize=20)\n",
    "    ax.annotate(text, xy=(x, y), xytext=(x+posX, y+posY), **kw)\n",
    "\n",
    "\n",
    "def figureCloses(data, atribute, createFigure=True, showAnnotate=True, subtitle=\"Preço de Fechamento do Bitcoin em USD\",\n",
    "                 fontsize=20, mask_yaxis='${x:,.0f}', annot_yaxis=30000, annot_xaxis=20000, annot_xaxis_pos=-65000, annot_yaxis_pos=20000, angle=0, angle_pos=0):\n",
    "    if createFigure:\n",
    "        plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.suptitle(subtitle, fontsize=fontsize)\n",
    "    plt.title(\"De {} Até {}\".format(\n",
    "        getFirstTimestamp(data), getLastTimestamp(data)), fontsize=14)\n",
    "    plt.grid()\n",
    "    plt.plot(data[atribute].values)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    if showAnnotate:\n",
    "        annot_max(0, data[atribute].values[0],\n",
    "                  annot_xaxis, annot_yaxis, angle, ax)\n",
    "        annot_max(len(data[atribute].values), data[atribute].values[-1],\n",
    "                  annot_xaxis_pos, annot_yaxis_pos, angle_pos, ax)\n",
    "\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.yaxis.set_major_formatter(ticker.StrMethodFormatter(mask_yaxis))\n",
    "\n",
    "\n",
    "def figureVolumeBtc(data, createFigure=True, showAnnotate=True, subtitle=\"Volume de movimentações do Bitcoin\"):\n",
    "    if createFigure:\n",
    "        plt.figure(figsize=(7, 3))\n",
    "\n",
    "    plt.suptitle(subtitle, fontsize=20)\n",
    "    # plt.title(\"De {} Até {}\".format(\n",
    "    #     firstTimestamp, lastTimestamp), fontsize=14)\n",
    "    plt.grid()\n",
    "    plt.plot(data)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    data2 = np.vectorize(lambda x: x if x >= 0 else 0)(data)\n",
    "    index = np.argmax(data2)\n",
    "    if showAnnotate:\n",
    "        annot_max(index, data2[index],\n",
    "                  100000, 0, \"angle,angleA=0,angleB=-5\", ax)\n",
    "        # annot_max(len(data), data[-1],\n",
    "        #           -65000, -20000, \"angle,angleA=0,angleB=-90\", ax)\n",
    "\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "\n",
    "\n",
    "def hasMissingData(timestampList):\n",
    "    \"\"\"\n",
    "    Verifica se possui intervalos diferentes de 60 segundos comparando o valor do iterador atual do array com o iterador anterior.\n",
    "\n",
    "    Parameters:\n",
    "        timestampList: Lista de valores timestamp -> list\n",
    "\n",
    "    Return:\n",
    "        False se não possui dados faltantes. True caso exista -> bool\n",
    "    \"\"\"\n",
    "    missing = []\n",
    "    for i in range(len(timestampList)):\n",
    "        if i > 0 and (timestampList[i] - timestampList[i - 1] != 60):\n",
    "            missing.append(\"{} {}\".format(i, datetime.fromtimestamp(\n",
    "                timestampList[i]), datetime.fromtimestamp(timestampList[i - 1])))\n",
    "\n",
    "    if len(missing) == 0:\n",
    "        return False\n",
    "\n",
    "    print(\"Intervalos sem registros:\")\n",
    "    for i in missing:\n",
    "        print(i)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def groupTimestampBy(data, format):\n",
    "    \"\"\"\n",
    "    Agrupa colula Timestamp através do formato passado.\n",
    "\n",
    "    Parameters:\n",
    "        data: Lista de valores timestamp -> list\n",
    "        format: Lista de valores timestamp -> string\n",
    "\n",
    "    Return:\n",
    "        data\n",
    "    \"\"\"\n",
    "    historical = data.dropna().reset_index(drop=True)\n",
    "    historical.TimestampFormated = pd.to_datetime(\n",
    "        historical.Timestamp, unit='s')\n",
    "    historical['dateFormated'] = historical.TimestampFormated.dt.strftime(\n",
    "        format)\n",
    "    return historical.groupby(historical.dateFormated).mean()\n",
    "\n",
    "\n",
    "def groupByMinute(data):\n",
    "    return groupTimestampBy(data, '%Y-%m-%d %H:MM')\n",
    "\n",
    "\n",
    "def groupByHour(data):\n",
    "    return groupTimestampBy(data, '%Y-%m-%d %H')\n",
    "\n",
    "\n",
    "def groupByDay(data):\n",
    "    return groupTimestampBy(data, '%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://storage.googleapis.com/kaggle-data-sets/1346/2109006/compressed/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20220806%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20220806T160240Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=33880e9241b4f37cdf5ac68e03cf03b743f79aeb668214b73540e1bf5ba406f7f1cfea212c1d2c69fd6f8257f067d3f73e28ab6f3245a22d4616b8e3a4dfaa6b7cca5c01619ee638821f9007c34282d990f5f3514047798ca70ea664b89a469cf1d4aead5d5613247744e6392022d85400d11c2b125eee434b5019d4099e36f6dc99b7628533d193390e2948a878e299032050b598eb0d9c7a3d113a997fbdf685e4da36d311200fa333fd456cdd9a43b1d114b70c2b0f02506367f61ae72b1220db408e569215eb31697fbdddfcb77e46638315e0d20149df31de53744e997a617ee6e39abf5e609faf4e33f289f2fcdd3e607a0cd7d2aaa2f82db60ac2e824\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "No debugger available, can not send 'disconnect'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Any results you write to the current directory are saved as output.\n",
    "import zipfile\n",
    "import requests\n",
    "import pathlib\n",
    "\n",
    "def downloadFile(url, filename): \n",
    "    print('Downloading from ' + url)\n",
    "    response = requests.get(url)\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "def downloadFileIfNotExists(url, isZip=False):\n",
    "    dir = './data/'\n",
    "    strHash = str(hash(url))\n",
    "    pathFile = dir + strHash\n",
    "    if (os.path.exists(pathFile)):\n",
    "        print('Reload file from cache')\n",
    "        return pathFile\n",
    "\n",
    "    downloadFile(url, pathFile)\n",
    "    if isZip:\n",
    "        tmp = './tmp'\n",
    "        os.makedirs(os.path.dirname(tmp), exist_ok=True)\n",
    "        with zipfile.ZipFile(pathFile, 'r') as zip_ref:\n",
    "            zip_ref.extractall(tmp + strHash)\n",
    "        pathFile = tmp + strHash + '/' + zip_ref.namelist()[0]\n",
    "        os.remove(pathFile)\n",
    "        os.rename(tmp + strHash, pathFile)\n",
    "        os.remove(tmp)\n",
    "\n",
    "    return pathFile\n",
    "\n",
    "# path_to_file = downloadFileIfNotExists('https://www.cryptodatadownload.com/cdd/Bitstamp_BTCUSD_1h.csv')\n",
    "path_to_file = downloadFileIfNotExists('https://storage.googleapis.com/kaggle-data-sets/1346/2109006/compressed/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20220806%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20220806T160240Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=33880e9241b4f37cdf5ac68e03cf03b743f79aeb668214b73540e1bf5ba406f7f1cfea212c1d2c69fd6f8257f067d3f73e28ab6f3245a22d4616b8e3a4dfaa6b7cca5c01619ee638821f9007c34282d990f5f3514047798ca70ea664b89a469cf1d4aead5d5613247744e6392022d85400d11c2b125eee434b5019d4099e36f6dc99b7628533d193390e2948a878e299032050b598eb0d9c7a3d113a997fbdf685e4da36d311200fa333fd456cdd9a43b1d114b70c2b0f02506367f61ae72b1220db408e569215eb31697fbdddfcb77e46638315e0d20149df31de53744e997a617ee6e39abf5e609faf4e33f289f2fcdd3e607a0cd7d2aaa2f82db60ac2e824', True)\n",
    "    \n",
    "    # raise Exception(\"File not found. Please download the file from the link below and place it in the data folder https://www.kaggle.com/datasets/mczielinski/bitcoin-historical-data\")\n",
    "\n",
    "coinbase = pd.read_csv(path_to_file, skiprows=1)\n",
    "coinbase = coinbase.rename(columns={\"unix\": \"Timestamp\", \"close\": \"Close\"})\n",
    "coinbase.describe()\n",
    "# coinbase.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrar intervalo de dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateDatabase(df):\n",
    "    if not 'Close' in df.columns:\n",
    "        raise Exception(\"Database does not have Close column\")\n",
    "    if not 'Timestamp' in df.columns:\n",
    "        raise Exception(\"Database does not have Timestamp column\")\n",
    "   # check if is valid timestamp\n",
    "    if not df.Timestamp.dtype == 'int64':\n",
    "        raise Exception(\"Database does not have valid Timestamp column\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "5e3cc7f80b254a02285b48ff3aa15b62a8347990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O intervalo entre datas é de 15/05/2018 03:00:00 até 15/05/2018 03:00:00, somando um total de 1 registros.\n"
     ]
    }
   ],
   "source": [
    "filtered = filterByInterval(coinbase, relativedelta(months=12))\n",
    "\n",
    "if hasMissingData(filtered['Timestamp'].values):\n",
    "    raise Exception(\"Missing data in the dataframe\")\n",
    "\n",
    "print(\"O intervalo entre datas é de {} até {}, somando um total de {} registros.\".format(\n",
    "    getFirstTimestamp(filtered), getLastTimestamp(filtered), filtered.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise e Exploração dos Dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepara os dados históricos agrupandos por hora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_per_day = groupByDay(filtered)\n",
    "historical_per_hour = groupByHour(filtered)\n",
    "historical_per_minute = groupByMinute(filtered)\n",
    "\n",
    "if showGraphs:\n",
    "    kw = dict(annot_yaxis=10000, annot_xaxis=-1000, annot_xaxis_pos=-6000, annot_yaxis_pos=-\n",
    "              8000, angle=\"angle,angleA=0,angleB=90\", angle_pos=\"angle,angleA=0,angleB=-90\", showAnnotate=True)\n",
    "    figureCloses(filtered, 'Close', **kw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico Volatility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volatiltyGraph(data):\n",
    "    returns = data.pct_change().dropna(axis=0)\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.title('BTC - Volatilidade')\n",
    "    plt.grid()\n",
    "    returns['Close'].plot(label='Close', color='blue',\n",
    "                          linewidth=2, alpha=0.8, legend=True)\n",
    "    plt.autoscale(tight=True)\n",
    "    plt.axhline(y=0, color='black')\n",
    "    plt.axhline(y=0.05, color='red')\n",
    "    plt.axhline(y=-0.05, color='red')\n",
    "    plt.axhline(y=0.1, color='red')\n",
    "    plt.axhline(y=-0.1, color='red')\n",
    "    plt.xlabel(None)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if showGraphs:\n",
    "    volatiltyGraph(historical_per_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmapGraph(data):\n",
    "    f, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.heatmap(data.corr(), annot=True,\n",
    "                linewidths=.9, fmt='.1f', ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if showGraphs:\n",
    "    heatmapGraph(historical_per_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dia da semana com valor mais baixo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowestDuringWeek(data):\n",
    "    data.Timestamp = pd.to_datetime(data.Timestamp, unit='s')\n",
    "    data = data.dropna()\n",
    "\n",
    "    week = {0: 'Seg', 1: 'Ter', 2: 'Qua',\n",
    "            3: 'Qui', 4: 'Sex', 5: 'Sab', 6: 'Dom'}\n",
    "    data['Dia da Semana'] = data['Timestamp'].dt.dayofweek.map(week)\n",
    "\n",
    "    # count min value for each week day\n",
    "    idx = data.groupby([pd.Grouper(key='Timestamp', freq='W-MON')]\n",
    "                       )['Close'].transform(min) == data['Close']\n",
    "\n",
    "    # data is still in minutes, so I calculate it for days.\n",
    "    lows_count = data[idx].groupby(\n",
    "        [pd.Grouper(key='Timestamp', freq='D')]).first().reset_index()\n",
    "    lows_count = lows_count.dropna()\n",
    "\n",
    "    sns.set(rc={'figure.figsize': (14, 6)})\n",
    "    ax = sns.countplot(x='Dia da Semana', data=lows_count, order=[\n",
    "                       'Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'Sab', 'Dom'])\n",
    "    ax.set(ylabel='Quantidade de vezes com valor mais baixo')\n",
    "\n",
    "\n",
    "if showGraphs:\n",
    "    lowestDuringWeek(historical_per_minute)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARAÇÃO DOS DADOS PARA OS MODELOS DE APRENDIZADO DE MÁQUINA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Open', 'Volume_(BTC)', 'Volume_(Currency)', 'Weighted_Price', 'High', 'Low'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/willian/github/bitcoin_prediction/btc-price-prediction-using-lstm.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/willian/github/bitcoin_prediction/btc-price-prediction-using-lstm.ipynb#ch0000015?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize\u001b[39m(scaler, values):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/willian/github/bitcoin_prediction/btc-price-prediction-using-lstm.ipynb#ch0000015?line=15'>16</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m scaler\u001b[39m.\u001b[39mfit_transform(np\u001b[39m.\u001b[39marray(values)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/willian/github/bitcoin_prediction/btc-price-prediction-using-lstm.ipynb#ch0000015?line=18'>19</a>\u001b[0m df \u001b[39m=\u001b[39m removeUnusedColumns(filtered\u001b[39m.\u001b[39;49mcopy())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/willian/github/bitcoin_prediction/btc-price-prediction-using-lstm.ipynb#ch0000015?line=19'>20</a>\u001b[0m df \u001b[39m=\u001b[39m groupByTimer(df, \u001b[39m'\u001b[39m\u001b[39m1H\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/willian/github/bitcoin_prediction/btc-price-prediction-using-lstm.ipynb#ch0000015?line=20'>21</a>\u001b[0m scaler \u001b[39m=\u001b[39m MinMaxScaler()\n",
      "\u001b[1;32m/home/willian/github/bitcoin_prediction/btc-price-prediction-using-lstm.ipynb Cell 19\u001b[0m in \u001b[0;36mremoveUnusedColumns\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/willian/github/bitcoin_prediction/btc-price-prediction-using-lstm.ipynb#ch0000015?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mremoveUnusedColumns\u001b[39m(df):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/willian/github/bitcoin_prediction/btc-price-prediction-using-lstm.ipynb#ch0000015?line=1'>2</a>\u001b[0m     df\u001b[39m.\u001b[39;49mdrop([\u001b[39m'\u001b[39;49m\u001b[39mOpen\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mVolume_(BTC)\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mVolume_(Currency)\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/willian/github/bitcoin_prediction/btc-price-prediction-using-lstm.ipynb#ch0000015?line=2'>3</a>\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mWeighted_Price\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mHigh\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mLow\u001b[39;49m\u001b[39m'\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/willian/github/bitcoin_prediction/btc-price-prediction-using-lstm.ipynb#ch0000015?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/github/bitcoin_prediction/venv/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/github/bitcoin_prediction/venv/lib/python3.10/site-packages/pandas/core/frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4806\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   4807\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   4808\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   4816\u001b[0m ):\n\u001b[1;32m   4817\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4818\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4952\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4954\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   4955\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   4956\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   4957\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   4958\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   4959\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   4960\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   4961\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   4962\u001b[0m     )\n",
      "File \u001b[0;32m~/github/bitcoin_prediction/venv/lib/python3.10/site-packages/pandas/core/generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4266\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4267\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4269\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/github/bitcoin_prediction/venv/lib/python3.10/site-packages/pandas/core/generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4310\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4311\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4312\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4314\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/github/bitcoin_prediction/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6643\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6644\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6645\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6646\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Open', 'Volume_(BTC)', 'Volume_(Currency)', 'Weighted_Price', 'High', 'Low'] not found in axis\""
     ]
    }
   ],
   "source": [
    "def removeUnusedColumns(df):\n",
    "    df.drop(['Open', 'Volume_(BTC)', 'Volume_(Currency)',\n",
    "            'Weighted_Price', 'High', 'Low'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def groupByTimer(df, interval):\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\n",
    "    df = df.set_index('Timestamp')\n",
    "    df = df.resample(interval).mean()\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize(scaler, values):\n",
    "    return scaler.fit_transform(np.array(values).reshape(-1, 1))\n",
    "\n",
    "\n",
    "df = removeUnusedColumns(filtered.copy())\n",
    "df = groupByTimer(df, '1H')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_close = normalize(scaler, df['Close'].values)\n",
    "scaled_close.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sequences(data, seq_len):\n",
    "    d = []\n",
    "    for index in range(len(data) - seq_len):\n",
    "        d.append(data[index: index + seq_len])\n",
    "\n",
    "    return np.array(d)\n",
    "\n",
    "\n",
    "def preprocess(dataset, loopBack, hoursToTest):\n",
    "    \"\"\"\n",
    "    Separa os dados de teste adicionando o loopback para os registros\n",
    "    Return: [batch_size, sequence_length, n_features]\n",
    "    \"\"\"\n",
    "    data = to_sequences(dataset, loopBack + 1)\n",
    "    num_train = len(dataset) - hoursToTest\n",
    "\n",
    "    X_train = data[:num_train, :-1, :]\n",
    "    y_train = data[:num_train, -1, :]\n",
    "    X_test = data[num_train:, :-1, :]\n",
    "    y_test = data[num_train:, -1, :]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "days = 15\n",
    "hours = 24\n",
    "SEPARATE_HOURS_TO_TEST = days * hours\n",
    "LOOP_BACK = 48\n",
    "\n",
    "trainX, trainY, testX, testY = preprocess(scaled_close, LOOP_BACK, SEPARATE_HOURS_TO_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(loop_back, dropout = 0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(CuDNNLSTM(loop_back, return_sequences=True), input_shape=(loop_back, trainX.shape[-1])))\n",
    "    model.add(Dropout(rate=dropout))\n",
    "    model.add(Bidirectional(CuDNNLSTM((loop_back * 2), return_sequences=True)))\n",
    "    model.add(Dropout(rate=dropout))\n",
    "    model.add(Bidirectional(CuDNNLSTM(loop_back, return_sequences=False)))\n",
    "    model.add(Dense(units=1))\n",
    "    model.add(Activation('linear'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(loop_back=LOOP_BACK, dropout=0.2)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "history = model.fit(\n",
    "    trainX, \n",
    "    trainY, \n",
    "    epochs=50,\n",
    "    batch_size=60,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[callback],\n",
    "    verbose=1\n",
    ")\n",
    "print('-----' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Função de Perda')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoca')\n",
    "plt.legend(['treino', 'teste'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testX.shape)\n",
    "print(testY.shape)\n",
    "\n",
    "\n",
    "y_hat = model.predict(testX)\n",
    "\n",
    "y_test_inverse = scaler.inverse_transform(testY)\n",
    "y_hat_inverse = scaler.inverse_transform(y_hat)\n",
    "\n",
    "plt.plot(y_test_inverse, label=\"Actual Price\", color='green')\n",
    "plt.plot(y_hat_inverse, label=\"Predicted Price\", color='red')\n",
    "\n",
    "plt.title('Bitcoin price prediction')\n",
    "plt.xlabel('Time [hours]')\n",
    "plt.ylabel('Price')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4580d54dad946c63f3231e475c6e128d208677f59b1aba948b92bd5c68c9ceb6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
