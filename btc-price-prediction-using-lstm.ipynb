{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt  # data visualization\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from functions import *\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "import statsmodels.api as sm\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "showGraphs = True\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "path_to_file = \"./data/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv\"\n",
    "\n",
    "if not (os.path.exists(path_to_file)):\n",
    "    raise Exception(\"File not found. Please download the file from the link below and place it in the data folder https://www.kaggle.com/datasets/mczielinski/bitcoin-historical-data\")\n",
    "\n",
    "coinbase = pd.read_csv(path_to_file)\n",
    "\n",
    "coinbase.describe()\n",
    "coinbase.tail()\n",
    "coinbase.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrar intervalo de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e3cc7f80b254a02285b48ff3aa15b62a8347990"
   },
   "outputs": [],
   "source": [
    "filtered = filterByInterval(coinbase, relativedelta(months=24))\n",
    "\n",
    "if hasMissingData(filtered['Timestamp'].values):\n",
    "    raise Exception(\"Missing data in the dataframe\")\n",
    "\n",
    "print(\"O intervalo entre datas é de {} até {}, somando um total de {} registros.\".format(\n",
    "    getFirstTimestamp(filtered), getLastTimestamp(filtered), filtered.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepara os dados históricos agrupandos por hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if showGraphs:\n",
    "    kw = dict(annot_yaxis=10000, annot_xaxis=-1000, annot_xaxis_pos=-6000, annot_yaxis_pos=-\n",
    "              8000, angle=\"angle,angleA=0,angleB=90\", angle_pos=\"angle,angleA=0,angleB=-90\")\n",
    "    figureCloses(filtered, 'Close', **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if showGraphs:\n",
    "    # kw = dict(showAnnotate=False)\n",
    "#     figureCloses(filtered, 'Volume_(BTC)', **kw)\n",
    "\n",
    "    # figureCloses(filtered, 'Volume_(Currency)', **kw)\n",
    "\n",
    "#     figureCloses(filtered, 'Weighted_Price', **kw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical = filtered.dropna().reset_index(drop=True)\n",
    "historical.Timestamp = pd.to_datetime(historical.Timestamp, unit='s')\n",
    "# historical['date'] = historical.Timestamp.dt.date\n",
    "historical['dateHour'] = historical.Timestamp.dt.strftime('%Y-%m-%d %H')\n",
    "historical_per_hour = historical.groupby(historical.dateHour).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize = (30,30))\n",
    "sns.pairplot(historical_per_hour, vars=['Close', 'Volume_(BTC)', 'Volume_(Currency)'])\n",
    "sns.pairplot(historical_per_hour, vars=['Close', 'High', 'Low', 'Weighted_Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filtered.Close\n",
    "data = data.values\n",
    "max = np.max(data)\n",
    "data = data/max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar dados de Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [data[i:i+10] for i in range(len(data)-11)]\n",
    "Y = [data[i+10] for i in range(len(data)-11)]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.25, shuffle=False)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "lstm = LSTM(64, activation='relu')\n",
    "\n",
    "model = Sequential([\n",
    "    Bidirectional(lstm, input_shape=(1, 10)),\n",
    "    Dropout(0.15),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(X_train, Y_train, epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train)\n",
    "\n",
    "print(\"Mean absolute error regression loss: %.4f\" %\n",
    "      mean_absolute_error(Y_train, pred_train))\n",
    "print(\"Root mean squared error regression loss: %.4f\" %\n",
    "      np.sqrt(mean_squared_error(Y_train, pred_train)))\n",
    "print(\"R2 score: %.4f\" % r2_score(Y_train, pred_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico da função de perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if showGraphs:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Loss evolution\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico da predição comparado com os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if showGraphs:\n",
    "    preds1 = pred_train * max\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.plot(Y_train * max, c='red', label='predicted values', linewidth=2)\n",
    "    plt.plot(preds1, c='blue', label='real values', linewidth=2)\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.title(\"prediction on train data\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico da predição comparado com os dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if showGraphs:\n",
    "    preds = model.predict(X_test) * max\n",
    "    plt.figure(figsize=(14, 14))\n",
    "    plt.plot(preds, c='red', label='predicted values', linewidth=2)\n",
    "    plt.plot(Y_test * max, c='blue', label='real values', linewidth=2)\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.title(\"prediction on test data\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "02066b178113dde23e3b55746623c34fe31742b6"
   },
   "source": [
    "Train using LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "97f2e44fbb694b24522bedd99f2c6a9e6d934f6f"
   },
   "outputs": [],
   "source": [
    "# # The LSTM architecture\n",
    "# regressor = Sequential()\n",
    "# # First LSTM layer with Dropout regularisation\n",
    "# regressor.add(LSTM(units=50, return_sequences=True,\n",
    "#               input_shape=(X_train.shape[1], 1)))\n",
    "# regressor.add(Dropout(0.2))\n",
    "\n",
    "# # Second LSTM layer\n",
    "# regressor.add(LSTM(units=50, return_sequences=True))\n",
    "# regressor.add(Dropout(0.2))\n",
    "\n",
    "# # Third LSTM layer\n",
    "# regressor.add(LSTM(units=50, return_sequences=True))\n",
    "# regressor.add(Dropout(0.5))\n",
    "\n",
    "# # Fourth LSTM layer\n",
    "# regressor.add(LSTM(units=50))\n",
    "# regressor.add(Dropout(0.5))\n",
    "\n",
    "# # The output layer\n",
    "# regressor.add(Dense(units=1))\n",
    "\n",
    "# # Compiling the RNN\n",
    "# regressor.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "# # Fitting to the training set\n",
    "# regressor.fit(X_train, y_train, epochs=1, batch_size=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f41fc0e9bb329ed6a2a3e44689590aae66f44d2"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ec7e65a7e8babcc2befccdb020f02d228343e4e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4db281d75bfbf413f1896d66740d2406d9d759e4"
   },
   "source": [
    "This is clearly overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
