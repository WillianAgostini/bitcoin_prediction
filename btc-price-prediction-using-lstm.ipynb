{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (2.28.1)\n",
      "Collecting zipfile36\n"
     ]
    }
   ],
   "source": [
    "!pip install requests zipfile36\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, Input, Embedding, Activation\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt  # data visualization\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from module import myFunctions\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "import statsmodels.api as sm\n",
    "import importlib\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import plotly.offline as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from itertools import cycle\n",
    "import math\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "\n",
    "def reloadMyModule():\n",
    "    importlib.reload(myFunctions)\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "showGraphs = False\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "# https://towardsdatascience.com/cryptocurrency-price-prediction-using-lstms-tensorflow-for-hackers-part-iii-264fcdbccd3f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "path_to_file = \"./data/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv\"\n",
    "\n",
    "if not (os.path.exists(path_to_file)):\n",
    "    import zipfile\n",
    "    import requests\n",
    "\n",
    "    cache = 'arquivocache.zip'\n",
    "    if not (os.path.exists(cache)):\n",
    "        url = 'https://storage.googleapis.com/kaggle-data-sets/1346/2109006/compressed/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20220731%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20220731T235107Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=289d08b6c270d9dce0bbf9ba1dbb8a8aed7eea563483ac0c0fcd1ad2cd94c36cac4923e01db7907aad10f482bd84f274aa2c4fb173f7ffa3ead1253a62d315b62fa719bba732726f22147899bce00ef26431182f3c9c0b5465f5f12c65483f3f5104152652df5764b5bc454bb0e90c0fbb6b7854ace7c7f2d60d02ba450509a5c1e488e739dc2b373cc04b9811b19b01ef9230a7dd6475af32399b8931342649281a2f581aacac4b187bfd1d04e113b3054b8878b01071ae1baa00e61b98bb99407bb88da3e9fa4c39d1084ef3ef2d778526adcd6791dce5520091ac64fa7bc986c57b98990efd75aa6305ea0634ecd241c54abb2ba77d8a98228bd3c210ebf4'\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(cache, 'wb').write(r.content)\n",
    "\n",
    "    with zipfile.ZipFile(cache, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data/')\n",
    "    \n",
    "    if os.path.exists(cache):\n",
    "        os.remove(cache)\n",
    "    \n",
    "    # raise Exception(\"File not found. Please download the file from the link below and place it in the data folder https://www.kaggle.com/datasets/mczielinski/bitcoin-historical-data\")\n",
    "\n",
    "coinbase = pd.read_csv(path_to_file)\n",
    "\n",
    "coinbase.describe()\n",
    "coinbase.tail()\n",
    "coinbase.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrar intervalo de dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e3cc7f80b254a02285b48ff3aa15b62a8347990"
   },
   "outputs": [],
   "source": [
    "filtered = myFunctions.filterByInterval(coinbase, relativedelta(months=12))\n",
    "\n",
    "if myFunctions.hasMissingData(filtered['Timestamp'].values):\n",
    "    raise Exception(\"Missing data in the dataframe\")\n",
    "\n",
    "print(\"O intervalo entre datas é de {} até {}, somando um total de {} registros.\".format(\n",
    "    myFunctions.getFirstTimestamp(filtered), myFunctions.getLastTimestamp(filtered), filtered.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise e Exploração dos Dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepara os dados históricos agrupandos por hora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_per_day = myFunctions.groupByDay(filtered)\n",
    "historical_per_hour = myFunctions.groupByHour(filtered)\n",
    "historical_per_minute = myFunctions.groupByMinute(filtered)\n",
    "\n",
    "if showGraphs:\n",
    "    kw = dict(annot_yaxis=10000, annot_xaxis=-1000, annot_xaxis_pos=-6000, annot_yaxis_pos=-\n",
    "              8000, angle=\"angle,angleA=0,angleB=90\", angle_pos=\"angle,angleA=0,angleB=-90\", showAnnotate=True)\n",
    "    myFunctions.figureCloses(filtered, 'Close', **kw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico Volatility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volatiltyGraph(data):\n",
    "    returns = data.pct_change().dropna(axis=0)\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.title('BTC - Volatilidade')\n",
    "    plt.grid()\n",
    "    returns['Close'].plot(label='Close', color='blue',\n",
    "                          linewidth=2, alpha=0.8, legend=True)\n",
    "    plt.autoscale(tight=True)\n",
    "    plt.axhline(y=0, color='black')\n",
    "    plt.axhline(y=0.05, color='red')\n",
    "    plt.axhline(y=-0.05, color='red')\n",
    "    plt.axhline(y=0.1, color='red')\n",
    "    plt.axhline(y=-0.1, color='red')\n",
    "    plt.xlabel(None)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if showGraphs:\n",
    "    volatiltyGraph(historical_per_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmapGraph(data):\n",
    "    f, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.heatmap(data.corr(), annot=True,\n",
    "                linewidths=.9, fmt='.1f', ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if showGraphs:\n",
    "    heatmapGraph(historical_per_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dia da semana com valor mais baixo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowestDuringWeek(data):\n",
    "    data.Timestamp = pd.to_datetime(data.Timestamp, unit='s')\n",
    "    data = data.dropna()\n",
    "\n",
    "    week = {0: 'Seg', 1: 'Ter', 2: 'Qua',\n",
    "            3: 'Qui', 4: 'Sex', 5: 'Sab', 6: 'Dom'}\n",
    "    data['Dia da Semana'] = data['Timestamp'].dt.dayofweek.map(week)\n",
    "\n",
    "    # count min value for each week day\n",
    "    idx = data.groupby([pd.Grouper(key='Timestamp', freq='W-MON')]\n",
    "                       )['Close'].transform(min) == data['Close']\n",
    "\n",
    "    # data is still in minutes, so I calculate it for days.\n",
    "    lows_count = data[idx].groupby(\n",
    "        [pd.Grouper(key='Timestamp', freq='D')]).first().reset_index()\n",
    "    lows_count = lows_count.dropna()\n",
    "\n",
    "    sns.set(rc={'figure.figsize': (14, 6)})\n",
    "    ax = sns.countplot(x='Dia da Semana', data=lows_count, order=[\n",
    "                       'Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'Sab', 'Dom'])\n",
    "    ax.set(ylabel='Quantidade de vezes com valor mais baixo')\n",
    "\n",
    "\n",
    "if showGraphs:\n",
    "    lowestDuringWeek(historical_per_minute)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARAÇÃO DOS DADOS PARA OS MODELOS DE APRENDIZADO DE MÁQUINA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloadMyModule()\n",
    "\n",
    "def removeUnusedColumns(df):\n",
    "    df.drop(['Open', 'Volume_(BTC)', 'Volume_(Currency)',\n",
    "            'Weighted_Price', 'High', 'Low'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def groupByTimer(df, interval):\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\n",
    "    df = df.set_index('Timestamp')\n",
    "    df = df.resample(interval).mean()\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize(scaler, values):\n",
    "    return scaler.fit_transform(np.array(values).reshape(-1, 1))\n",
    "\n",
    "\n",
    "df = removeUnusedColumns(filtered.copy())\n",
    "df = groupByTimer(df, '1H')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df['Close'] = normalize(scaler, df['Close'])\n",
    "scaled_close = df['Close']\n",
    "scaled_close.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(dataset):\n",
    "    return dataset.reshape(dataset.shape[0],dataset.shape[1] , 1)\n",
    "\n",
    "\n",
    "def create_dataset(dataset, loop_back=1):\n",
    "    \"\"\"\n",
    "    Estrutura os dados da maneira correta para o treinamento da rede\n",
    "    \"\"\"\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - loop_back):\n",
    "        dataX.append(dataset[i:(i + loop_back)])\n",
    "        dataY.append(dataset[i + loop_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "def separateTrainTest(dataset, projection_Hours):\n",
    "    \"\"\" \n",
    "    Separa o dataset em treino e teste.\n",
    "    Para isso, o dataset é dividido em duas partes:\n",
    "    1. A primeira parte é usada para treino.\n",
    "    2. A segunda parte é usada para teste.\n",
    "    \"\"\"\n",
    "    df_train = dataset[:len(dataset)-projection_Hours].values\n",
    "    df_test = dataset[len(dataset)-projection_Hours:].values\n",
    "    print(\"{0:0.2f}% separado para teste\".format((len(df_test)*100)/len(dataset)))\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "dias = 15\n",
    "hours = 24\n",
    "PROJECTION_HOURS = 48\n",
    "\n",
    "df_train, df_test = separateTrainTest(scaled_close, dias * hours)\n",
    "trainX, trainY = create_dataset(df_train, PROJECTION_HOURS)\n",
    "testX, testY = create_dataset(df_test, PROJECTION_HOURS)\n",
    "\n",
    "trainX, testX = reshape(trainX), reshape(testX)\n",
    "\n",
    "print(\"X_train: \", trainX.shape)\n",
    "print(\"X_test: \", testX.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.2\n",
    "WINDOW_SIZE = PROJECTION_HOURS\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(WINDOW_SIZE, return_sequences=True),\n",
    "                        input_shape=(WINDOW_SIZE, trainX.shape[-1])))\n",
    "model.add(Dropout(rate=DROPOUT))\n",
    "model.add(Bidirectional(LSTM((WINDOW_SIZE * 2), return_sequences=True)))\n",
    "model.add(Dropout(rate=DROPOUT))\n",
    "model.add(Bidirectional(LSTM(WINDOW_SIZE, return_sequences=False)))\n",
    "model.add(Dense(units=1))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "history = model.fit(trainX, trainY, epochs = 2, batch_size =50, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(testX)\n",
    "\n",
    "y_test_inverse = scaler.inverse_transform(testY)\n",
    "y_hat_inverse = scaler.inverse_transform(y_hat)\n",
    " \n",
    "plt.plot(y_test_inverse, label=\"Actual Price\", color='green')\n",
    "plt.plot(y_hat_inverse, label=\"Predicted Price\", color='red')\n",
    " \n",
    "plt.title('Bitcoin price prediction')\n",
    "plt.xlabel('Time [days]')\n",
    "plt.ylabel('Price')\n",
    "plt.legend(loc='best')\n",
    " \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4580d54dad946c63f3231e475c6e128d208677f59b1aba948b92bd5c68c9ceb6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
